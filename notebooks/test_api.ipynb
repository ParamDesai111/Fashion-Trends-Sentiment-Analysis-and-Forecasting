{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "# Load configuration\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('../config/config.ini')\n",
    "\n",
    "# Twitter API credentials\n",
    "API_KEY = config['TWITTER_API']['API_KEY']\n",
    "API_SECRET = config['TWITTER_API']['API_SECRET']\n",
    "ACCESS_TOKEN = config['TWITTER_API']['ACCESS_TOKEN']\n",
    "ACCESS_SECRET = config['TWITTER_API']['ACCESS_SECRET']\n",
    "BEARER_TOKEN = config['TWITTER_API']['BEARER_TOKEN']\n",
    "\n",
    "# Azure Event Hub Kafka settings\n",
    "KAFKA_BROKER = config['AZURE_EVENTHUB']['BROKER']\n",
    "EVENT_HUB_NAME = config['AZURE_EVENTHUB']['EVENT_HUB_NAME']\n",
    "KAFKA_SASL_USERNAME = config['AZURE_EVENTHUB']['SASL_USERNAME']\n",
    "KAFKA_SASL_PASSWORD = config['AZURE_EVENTHUB']['SASL_PASSWORD']\n",
    "\n",
    "# Reddit API Settings\n",
    "REDDIT_CLIENT_ID = config['REDDIT_API']['CLIENT_ID']\n",
    "REDDIT_CLIENT_SECRET = config['REDDIT_API']['CLIENT_SECRET']\n",
    "REDDIT_USER_AGENT = config['REDDIT_API']['USER_AGENT']\n",
    "REDDIT_USERNAME = config['REDDIT_API']['USERNAME']\n",
    "REDDIT_PASSWORD = config['REDDIT_API']['PASSWORD']\n",
    "\n",
    "print(\"Config loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful!\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Test authentication\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                created_at  \\\n",
      "0  1869087265127125142 2024-12-17 18:28:24+00:00   \n",
      "1  1869087235427172369 2024-12-17 18:28:17+00:00   \n",
      "2  1869087207174328518 2024-12-17 18:28:10+00:00   \n",
      "3  1869087182184689829 2024-12-17 18:28:04+00:00   \n",
      "4  1869087157920600371 2024-12-17 18:27:59+00:00   \n",
      "5  1869087150886867395 2024-12-17 18:27:57+00:00   \n",
      "6  1869087145358712856 2024-12-17 18:27:56+00:00   \n",
      "7  1869087143500648723 2024-12-17 18:27:55+00:00   \n",
      "8  1869087122965381609 2024-12-17 18:27:50+00:00   \n",
      "9  1869087119135895917 2024-12-17 18:27:49+00:00   \n",
      "\n",
      "                                                text  \n",
      "0  Checkout on this shop on Shopee! Fashion  http...  \n",
      "1  @Spread_Star @voguebusiness @Khulood_Almani @S...  \n",
      "2  I paid for express shipping, and Fashion Nova ...  \n",
      "3  @Ashy_slashee Hmmm... ü§î\\n\\nIt's a tough one th...  \n",
      "4  üåüHOT HOT earn more with our crypto pump! $BTC ...  \n",
      "5  they're stronger than me because if i had the ...  \n",
      "6  i keep a copy of K&amp;R C in russian as a fas...  \n",
      "7  @Versace Delightfully invited to Versace's Spr...  \n",
      "8  @TheTitanBaddie @rihnavyannagggb Singing, danc...  \n",
      "9  @colossusPhD Airline gourmet meal consumption....  \n"
     ]
    }
   ],
   "source": [
    "client = tweepy.Client(bearer_token=BEARER_TOKEN, consumer_key=API_KEY, consumer_secret=API_SECRET, access_token=ACCESS_TOKEN, access_token_secret=ACCESS_SECRET)\n",
    "auth = tweepy.OAuth2BearerHandler(BEARER_TOKEN)\n",
    "api = tweepy.API(auth)\n",
    "# Search for recent tweets\n",
    "query = \"fashion -is:retweet lang:en\"  # Keywords + filter for retweets\n",
    "response = client.search_recent_tweets(query=query, max_results=10, tweet_fields=[\"created_at\", \"text\"])\n",
    "\n",
    "# Parse and store data\n",
    "data = []\n",
    "if response.data:\n",
    "    for tweet in response.data:\n",
    "        data.append({\n",
    "            \"id\": tweet.id,\n",
    "            \"created_at\": tweet.created_at,\n",
    "            \"text\": tweet.text\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Checkout on this shop on Shopee! Fashion  https://t.co/XLTOcf7ygW: https://t.co/sygAl8rFQD'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "# Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_CLIENT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT,\n",
    "    redirect_uri=\"http://localhost\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WAYWT (What Are You Wearing This Week?) - 23 O...</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1.729688e+09</td>\n",
       "      <td>WAYWT = What Are You Wearing This Week (or a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚û°Ô∏è Daily Simple Questions ‚¨ÖÔ∏è- Style feedback a...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.734455e+09</td>\n",
       "      <td>Welcome to the Daily Questions thread for all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I've held my tongue as long as I can.</td>\n",
       "      <td>405</td>\n",
       "      <td>125</td>\n",
       "      <td>1.734420e+09</td>\n",
       "      <td>Some of the questions that get asked here are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Does anyone know what this suit jacket style i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.734460e+09</td>\n",
       "      <td>[https://imgur.com/a/9SDo8Jw](https://imgur.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tom Ford Oud Wood - 1.7oz</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.734460e+09</td>\n",
       "      <td>Tom Ford Oud Wood - 1.7oz for $110 from Costco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score  num_comments  \\\n",
       "0  WAYWT (What Are You Wearing This Week?) - 23 O...      6            23   \n",
       "1  ‚û°Ô∏è Daily Simple Questions ‚¨ÖÔ∏è- Style feedback a...      1             4   \n",
       "2              I've held my tongue as long as I can.    405           125   \n",
       "3  Does anyone know what this suit jacket style i...      2             0   \n",
       "4                          Tom Ford Oud Wood - 1.7oz      2             0   \n",
       "\n",
       "    created_utc                                           selftext  \n",
       "0  1.729688e+09  WAYWT = What Are You Wearing This Week (or a d...  \n",
       "1  1.734455e+09  Welcome to the Daily Questions thread for all ...  \n",
       "2  1.734420e+09  Some of the questions that get asked here are ...  \n",
       "3  1.734460e+09  [https://imgur.com/a/9SDo8Jw](https://imgur.co...  \n",
       "4  1.734460e+09  Tom Ford Oud Wood - 1.7oz for $110 from Costco...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subreddit to analyze\n",
    "subreddit = reddit.subreddit(\"malefashionadvice\")\n",
    "\n",
    "# Fetch posts from 'hot', 'new', or 'top'\n",
    "posts = []\n",
    "for post in subreddit.hot(limit=100):  # Change limit as needed\n",
    "    posts.append({\n",
    "        \"title\": post.title,\n",
    "        \"score\": post.score,\n",
    "        \"num_comments\": post.num_comments,\n",
    "        \"created_utc\": post.created_utc,\n",
    "        \"selftext\": post.selftext\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(posts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Looking to get my first proper (ie. not ‚Äúsmart‚Äù) watch for nicer outfits. Being both a Swiss design and rail travel aficionado, a Mondaine Swiss Rail clock watch seems perfect for my taste. Any opinions on them? Good quality for the price? Long lasting?'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['selftext'][99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images in Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reddit_posts(subreddit_name, num_posts=20, num_comments=3):\n",
    "    \"\"\"\n",
    "    Fetch posts from a subreddit, including images, galleries, subreddit section, and top comments.\n",
    "\n",
    "    :param subreddit_name: Name of the subreddit to fetch data from.\n",
    "    :param num_posts: Number of posts to fetch.\n",
    "    :param num_comments: Number of top comments to fetch per post.\n",
    "    :return: DataFrame with Reddit post details (title, content, images, gallery, URL, section, top comments).\n",
    "    \"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "\n",
    "    # Updated regex to include jpeg, jpg, png, gif, imgur links\n",
    "    image_regex = r\"(https?://(?:i\\.)?imgur\\.com/[a-zA-Z0-9]+(?:\\.jpg|\\.jpeg|\\.png|\\.gif)?|\" \\\n",
    "                  r\"https?://.*\\.(jpg|jpeg|png|gif))\"\n",
    "\n",
    "    # Fetch posts from the 'hot' section\n",
    "    for submission in subreddit.hot(limit=num_posts):\n",
    "        post_images = []\n",
    "\n",
    "        # Extract image URLs from the post URL\n",
    "        if submission.url:\n",
    "            if re.search(image_regex, submission.url):\n",
    "                post_images.append(submission.url)\n",
    "\n",
    "        # Extract image links from the post's selftext\n",
    "        if submission.selftext:\n",
    "            images_in_text = re.findall(image_regex, submission.selftext)\n",
    "            post_images.extend([img[0] for img in images_in_text])\n",
    "\n",
    "        # Extract gallery images if the post contains a gallery\n",
    "        if hasattr(submission, \"gallery_data\") and submission.gallery_data:\n",
    "            media_metadata = submission.media_metadata\n",
    "            for item in submission.gallery_data[\"items\"]:\n",
    "                media_id = item[\"media_id\"]\n",
    "                if media_id in media_metadata:\n",
    "                    img_url = media_metadata[media_id][\"s\"][\"u\"]\n",
    "                    post_images.append(img_url)\n",
    "\n",
    "        # Remove duplicates in image links\n",
    "        post_images = list(set(post_images))\n",
    "\n",
    "        # Fetch top comments\n",
    "        top_comments = []\n",
    "        submission.comment_sort = \"best\"\n",
    "        submission.comments.replace_more(limit=0)  # Remove \"more comments\" placeholders\n",
    "        for comment in submission.comments[:num_comments]:\n",
    "            if comment.body:\n",
    "                top_comments.append(comment.body.strip())\n",
    "\n",
    "        # Store post details\n",
    "        post_data = {\n",
    "            \"title\": submission.title,\n",
    "            \"content\": submission.selftext,\n",
    "            \"images\": \", \".join(post_images) if post_images else None,\n",
    "            \"url\": submission.url,\n",
    "            \"section\": \"hot\",\n",
    "            \"top_comments\": \" | \".join(top_comments) if top_comments else None\n",
    "        }\n",
    "        posts.append(post_data)\n",
    "\n",
    "    # Convert to a DataFrame\n",
    "    df = pd.DataFrame(posts)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tc/hg976np16n7_h4z6hh2mznb80000gq/T/ipykernel_54431/1267574447.py:45: UserWarning: The comments for this submission have already been fetched, so the updated comment_sort will not have any effect.\n",
      "  submission.comment_sort = \"best\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 20 posts from r/femalefashionadvice (hot section).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>images</th>\n",
       "      <th>url</th>\n",
       "      <th>section</th>\n",
       "      <th>top_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fashion news - December 23, 2024</td>\n",
       "      <td>Here you can share all the fashion related new...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weird Little Outfits: An Inspo Album</td>\n",
       "      <td></td>\n",
       "      <td>https://preview.redd.it/9fdl3z112j9e1.jpg?widt...</td>\n",
       "      <td>https://www.reddit.com/gallery/1hnz49h</td>\n",
       "      <td>hot</td>\n",
       "      <td>Oh this is so so fun. I think I need that yell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there any fashion brands you love right no...</td>\n",
       "      <td>sometimes a brand just feels right. i‚Äôm curiou...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>[Sea](https://sea-ny.com/pages/pre-fall?_sc=1)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daily Questions Thread December 28, 2024</td>\n",
       "      <td>This  thread is for individual style questions...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>Hello! I‚Äôm looking into a Max Mara coat (weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wearing the clothes vs the clothes wearing you</td>\n",
       "      <td>Hi guys! \\n\\nWhat are your thoughts on styling...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>I wear a lot of stuff that could be described ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                   Fashion news - December 23, 2024   \n",
       "1               Weird Little Outfits: An Inspo Album   \n",
       "2  Are there any fashion brands you love right no...   \n",
       "3           Daily Questions Thread December 28, 2024   \n",
       "4     Wearing the clothes vs the clothes wearing you   \n",
       "\n",
       "                                             content  \\\n",
       "0  Here you can share all the fashion related new...   \n",
       "1                                                      \n",
       "2  sometimes a brand just feels right. i‚Äôm curiou...   \n",
       "3  This  thread is for individual style questions...   \n",
       "4  Hi guys! \\n\\nWhat are your thoughts on styling...   \n",
       "\n",
       "                                              images  \\\n",
       "0                                               None   \n",
       "1  https://preview.redd.it/9fdl3z112j9e1.jpg?widt...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                                 url section  \\\n",
       "0  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "1             https://www.reddit.com/gallery/1hnz49h     hot   \n",
       "2  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "3  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "4  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "\n",
       "                                        top_comments  \n",
       "0                                               None  \n",
       "1  Oh this is so so fun. I think I need that yell...  \n",
       "2  [Sea](https://sea-ny.com/pages/pre-fall?_sc=1)...  \n",
       "3  Hello! I‚Äôm looking into a Max Mara coat (weeke...  \n",
       "4  I wear a lot of stuff that could be described ...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_name = \"femalefashionadvice\"\n",
    "num_posts = 20\n",
    "num_comments = 3\n",
    "\n",
    "# Call the updated function\n",
    "reddit_df = fetch_reddit_posts(subreddit_name, num_posts, num_comments)\n",
    "print(f\"Fetched {len(reddit_df)} posts from r/{subreddit_name} (hot section).\")\n",
    "\n",
    "# Display the DataFrame\n",
    "reddit_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://preview.redd.it/35gpak26go9e1.png?width=1170&format=png&auto=webp&s=0a539a6d8d60246c0636e97e607a982e82ea4f6f\\n\\nFound a Harris Tweed Balmacaan for $150. This is the tag attached. Seems to be a vintage(?) Sears tag. Does anyone have any idea if this line of clothes are good quality or not?\\n\\nIt comes with the Harris tweed seal. | who makes the best elevated mens basics nowadays? I\\'m trying to buy higher quality garments and looking for a slightly elevated uniqlo. \\n\\nIt seems to me that many of the brands in this category start specializing but don\\'t have the breadth that uniqlo has... (ie, colorful standard for crewnecks, A&F for jeans, ec) | Hello! I am looking for something that has the oversized sweater feel, but issue is that I am a tall (6\\'3\") broad-shouldered person already. So in the past when I buy sweaters hoping they\\'ll fit me in this way they end up usually too short in the body when I\\'m actively looking for it to be too long in the body.\\n\\n\\nAny brands you know of that have long body sweaters would be appreciated! Thank you'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df['top_comments'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Param/Desktop/Coding/Projects/FashionTrendsProject/Fashion-Trends-Sentiment-Analysis-and-Forecasting/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/Param/Desktop/Coding/Projects/FashionTrendsProject/Fashion-Trends-Sentiment-Analysis-and-Forecasting/venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/var/folders/tc/hg976np16n7_h4z6hh2mznb80000gq/T/ipykernel_54431/3570625698.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"../ImageProcessingTool/notebooks/resnet18_fashion.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Define the transform for preprocessing\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to match model input size\n",
    "\n",
    "    transforms.ToTensor(),          # Convert image to tensor\n",
    "\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],  # Normalization mean (ImageNet values)\n",
    "\n",
    "        std=[0.229, 0.224, 0.225]    # Normalization std (ImageNet values)\n",
    "\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "# Assume the model is already loaded\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 45)  # Adjust for the number of categories\n",
    "model.load_state_dict(torch.load(\"../ImageProcessingTool/notebooks/resnet18_fashion.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "\n",
    "# Preprocessing function (assume it's defined)\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure 3-channel RGB\n",
    "    image = transform(image)\n",
    "    return image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Prediction function\n",
    "def predict_with_confidence(image_path, model, categories):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path).to(device)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = F.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "        confidence, predicted = torch.max(probabilities, 1)  # Get max confidence and class index\n",
    "    \n",
    "    return categories[predicted.item()], confidence.item()\n",
    "\n",
    "# Helper function to download an image from a URL\n",
    "def download_image(url, save_dir=\"images\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        filename = os.path.join(save_dir, url.split(\"/\")[-1])\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Categories for prediction\n",
    "categories = ['Topwear', 'Flip Flops', 'Water Bottle', 'Bath and Body', 'Shoes', 'Watches', 'Lips', 'Scarves', \n",
    "              'Innerwear', 'Wristbands', 'Skin Care', 'Ties', 'Umbrellas', 'Headwear', 'Loungewear and Nightwear', \n",
    "              'Beauty Accessories', 'Eyewear', 'Mufflers', 'Free Gifts', 'Nails', 'Bottomwear', 'Wallets', 'Saree', \n",
    "              'Dress', 'Cufflinks', 'Home Furnishing', 'Vouchers', 'Jewellery', 'Apparel Set', 'Perfumes', 'Makeup', \n",
    "              'Belts', 'Fragrance', 'Skin', 'Sports Accessories', 'Socks', 'Bags', 'Eyes', 'Shoe Accessories', \n",
    "              'Sandal', 'Gloves', 'Stoles', 'Accessories', 'Hair', 'Sports Equipment']\n",
    "\n",
    "# Process images in the DataFrame\n",
    "def process_images_in_dataframe(df, image_column=\"images\"):\n",
    "    processed_results = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        image_urls = row[image_column]\n",
    "        if pd.isna(image_urls):\n",
    "            processed_results.append(None)\n",
    "            continue\n",
    "\n",
    "        predictions = []\n",
    "        for url in image_urls.split(\", \"):  # Handle multiple image URLs\n",
    "            image_path = download_image(url)\n",
    "            if image_path:\n",
    "                try:\n",
    "                    predicted_category, confidence = predict_with_confidence(image_path, model, categories)\n",
    "                    predictions.append(f\"{predicted_category} ({confidence:.2f})\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {image_path}: {e}\")\n",
    "            else:\n",
    "                predictions.append(None)\n",
    "\n",
    "        # Combine predictions for all images in the row\n",
    "        processed_results.append(\", \".join(filter(None, predictions)))\n",
    "\n",
    "    # Add the predictions to a new column in the DataFrame\n",
    "    df[\"images_processed\"] = processed_results\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>images</th>\n",
       "      <th>url</th>\n",
       "      <th>section</th>\n",
       "      <th>top_comments</th>\n",
       "      <th>images_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fashion news - December 23, 2024</td>\n",
       "      <td>Here you can share all the fashion related new...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weird Little Outfits: An Inspo Album</td>\n",
       "      <td></td>\n",
       "      <td>https://preview.redd.it/9fdl3z112j9e1.jpg?widt...</td>\n",
       "      <td>https://www.reddit.com/gallery/1hnz49h</td>\n",
       "      <td>hot</td>\n",
       "      <td>Oh this is so so fun. I think I need that yell...</td>\n",
       "      <td>Loungewear and Nightwear (0.59), Loungewear an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there any fashion brands you love right no...</td>\n",
       "      <td>sometimes a brand just feels right. i‚Äôm curiou...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>[Sea](https://sea-ny.com/pages/pre-fall?_sc=1)...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Daily Questions Thread December 28, 2024</td>\n",
       "      <td>This  thread is for individual style questions...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>Hello! I‚Äôm looking into a Max Mara coat (weeke...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wearing the clothes vs the clothes wearing you</td>\n",
       "      <td>Hi guys! \\n\\nWhat are your thoughts on styling...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.reddit.com/r/femalefashionadvice/c...</td>\n",
       "      <td>hot</td>\n",
       "      <td>I wear a lot of stuff that could be described ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                   Fashion news - December 23, 2024   \n",
       "1               Weird Little Outfits: An Inspo Album   \n",
       "2  Are there any fashion brands you love right no...   \n",
       "3           Daily Questions Thread December 28, 2024   \n",
       "4     Wearing the clothes vs the clothes wearing you   \n",
       "\n",
       "                                             content  \\\n",
       "0  Here you can share all the fashion related new...   \n",
       "1                                                      \n",
       "2  sometimes a brand just feels right. i‚Äôm curiou...   \n",
       "3  This  thread is for individual style questions...   \n",
       "4  Hi guys! \\n\\nWhat are your thoughts on styling...   \n",
       "\n",
       "                                              images  \\\n",
       "0                                               None   \n",
       "1  https://preview.redd.it/9fdl3z112j9e1.jpg?widt...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                                 url section  \\\n",
       "0  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "1             https://www.reddit.com/gallery/1hnz49h     hot   \n",
       "2  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "3  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "4  https://www.reddit.com/r/femalefashionadvice/c...     hot   \n",
       "\n",
       "                                        top_comments  \\\n",
       "0                                               None   \n",
       "1  Oh this is so so fun. I think I need that yell...   \n",
       "2  [Sea](https://sea-ny.com/pages/pre-fall?_sc=1)...   \n",
       "3  Hello! I‚Äôm looking into a Max Mara coat (weeke...   \n",
       "4  I wear a lot of stuff that could be described ...   \n",
       "\n",
       "                                    images_processed  \n",
       "0                                               None  \n",
       "1  Loungewear and Nightwear (0.59), Loungewear an...  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming `reddit_df` is your DataFrame with the 'images' column\n",
    "reddit_df_with_predictions = process_images_in_dataframe(reddit_df, image_column=\"images\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "reddit_df_with_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df.to_csv('reddit_data.csv', index=False)\n",
    "reddit_df_with_predictions.to_csv('reddit_data_with_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
